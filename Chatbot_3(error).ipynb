{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5+1muSUrvfeEveVP3Qlwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek203/E-Abhishek/blob/master/Chatbot_3(error).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hec-Wv753dkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "import re\n",
        "import time\n",
        "import io\n",
        "import os\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, concatenate, Reshape\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrUMLPcdzt6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = \"/content/Chatbot_data.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyQDyT-izypN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = io.open(path_to_file,errors = 'ignore').read().strip().split('- - ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd4dsLnHz9CL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_question = []\n",
        "raw_ans = []\n",
        "for i in range(len(data)):\n",
        "    pair = data[i].split('  - ')\n",
        "    for j in range(len(pair)-1):\n",
        "        raw_question.append(pair[0])\n",
        "        raw_ans.append(pair[j+1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5VnTTJy0B0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "\n",
        "    text = text.lower()\n",
        "    \n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0htXv10B0GEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_questions = []\n",
        "for question in raw_question:\n",
        "    clean_questions.append(clean_text(question))\n",
        "    \n",
        "clean_answers = []    \n",
        "for answer in raw_ans:\n",
        "    clean_answers.append(clean_text(answer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wfL5z7Q0Hls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question = []\n",
        "ans = []\n",
        "for i in range(len(clean_questions)):\n",
        "  question.append('<start> '+ clean_questions[i] +' <end>')\n",
        "for i in range(len(clean_answers)):\n",
        "  ans.append('<start> '+ clean_answers[i] +' <end>')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om1iAmmP0S6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',num_words=1000,oov_token='<oov>')\n",
        "\n",
        "tokenizer.fit_on_texts(question)\n",
        "question_seq = tokenizer.texts_to_sequences(question)\n",
        "question_seq = tf.keras.preprocessing.sequence.pad_sequences(question_seq,padding='post')\n",
        "tokenizer.fit_on_texts(ans)\n",
        "ans_seq = tokenizer.texts_to_sequences(ans)\n",
        "ans_seq = tf.keras.preprocessing.sequence.pad_sequences(ans_seq, padding = 'post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ckOzKZh0Xrc",
        "colab_type": "code",
        "outputId": "8a01206a-d327-4534-d996-2e9b9e3d53ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len_input_seq = len(question_seq[0])\n",
        "len_output_seq = len(ans_seq[0])\n",
        "print(len(ans))\n",
        "\n",
        "BUFFER_SIZE = len(question_seq)\n",
        "batch_size = 64\n",
        "BATCH_SIZE = 64\n",
        "epochs = 10\n",
        "steps_per_epoch = len(question_seq)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 256\n",
        "vocab_inp_size = len(tokenizer.word_index)+1\n",
        "vocab_tar_size = len(tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((question_seq, ans_seq)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2rSObIBGFkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_question = Embedding(vocab_inp_size,embedding_dim)\n",
        "embedding_answer = Embedding(vocab_tar_size,embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykqkNS-o9UKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_inputs = Input(shape = (len_input_seq,))\n",
        "enc_inputs1 = embedding_question(enc_inputs)\n",
        "encoder = LSTM(units, return_state=True,return_sequences=True)\n",
        "enc_outputs, state_h, state_c = encoder(enc_inputs1)\n",
        "enc_states = [state_h,state_c]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTXRLQbM9t2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "\n",
        "    self.V1 = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query1, values):\n",
        "    query1_with_time_axis = tf.expand_dims(query1, 1)\n",
        "\n",
        "    score1 = self.V1(tf.nn.tanh(self.W1(query1_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    attention_weights1 = tf.nn.softmax(score1, axis=1)\n",
        "\n",
        "    context_vector1 = attention_weights1 * values\n",
        "\n",
        "    context_vector1 = tf.reduce_sum(context_vector1, axis=1)\n",
        "\n",
        "    return context_vector1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsZ38uoA9zX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dec_inputs = Input(shape = (len_output_seq,))\n",
        "dec_inputs1 = embedding_answer(dec_inputs)\n",
        "#attention = BahdanauAttention(10)\n",
        "\n",
        "#context_vec_1= BahdanauAttention(state_h,enc_outputs)\n",
        "#dec_inputs = tf.concat([tf.expand_dim(context_vec_1,1),dec_inputs],axis = -1)\n",
        "\n",
        "decode_lstm = LSTM(units,return_sequences=True,return_state=True)\n",
        "\n",
        "dec_outputs1,_,_ = decode_lstm(dec_inputs1,enc_states)\n",
        "#dec_outputs = tf.reshape(output, (-1, dec_outputs.shape[2]))\n",
        "dec_reshape = Reshape((len_output_seq,))\n",
        "dec_outputs1 = dec_reshape(dec_outputs1)\n",
        "dec_dense = Dense(len_output_seq,activation = 'softmax')\n",
        "dec_outputs = dec_dense(dec_outputs1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bxd5wkhC0GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([enc_inputs, dec_inputs], dec_outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFcRm3UzcSNr",
        "colab_type": "code",
        "outputId": "01a40a1e-88cd-4b61-df62-d271f4b7718d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    567808      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 256)    567808      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, None, 256),  525312      embedding_2[7][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, None, 44)     11308       lstm_9[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,197,548\n",
            "Trainable params: 2,197,548\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grLXzcFTBgM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tuAWfjPEAnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input_data = ans_seq\n",
        "\n",
        "decoder_target_data = []\n",
        "n = len(ans_seq)\n",
        "for i in range(n):\n",
        "  decoder_target_data.append(ans_seq[i][1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiLIdFaOEyyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans_seq[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUU8RdGEFn8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_target_data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFM8tprIDCSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.fit(input = [question_seq, decoder_input_data],output = decoder_target_data, epochs=epochs,batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}