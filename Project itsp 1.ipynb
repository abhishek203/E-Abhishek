{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek203/E-Abhishek/blob/master/Project%20itsp%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jWTBYRojKQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import load_img\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7i-JZyDR-XG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dowloading the file from github\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'facial_expressions-master.zip', origin='https://codeload.github.com/muxspace/facial_expressions/zip/master',\n",
        "    extract=True)\n",
        "\n",
        "path_to_csvfile = os.path.dirname(path_to_zip)+\"/facial_expressions-master/data/legend.csv\"\n",
        "path_to_images = os.path.dirname(path_to_zip) + \"/facial_expressions-master/images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzGhz6egAVh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = os.path.dirname(path_to_zip) + \"/facial_expressions-master/images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl7nFZPaVG3H",
        "colab_type": "code",
        "outputId": "e1811d45-565a-48d6-bc2b-cb01c5361472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "file = pd.read_csv(path_to_csvfile)\n",
        "legend = file.sort_values(by=['image'])\n",
        "legend.replace({'emotion':str.lower} )"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user.id</th>\n",
              "      <th>image</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>302</td>\n",
              "      <td>AJ_Cook_0001.jpg</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>302</td>\n",
              "      <td>AJ_Lamas_0001.jpg</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dwdii</td>\n",
              "      <td>Aaron_Eckhart_0001.jpg</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>302</td>\n",
              "      <td>Aaron_Guiel_0001.jpg</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>302</td>\n",
              "      <td>Aaron_Patterson_0001.jpg</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12768</th>\n",
              "      <td>dwdii</td>\n",
              "      <td>Zydrunas_Ilgauskas_0001.jpg</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>628</td>\n",
              "      <td>facial-expressions_2868582k.jpg</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>628</td>\n",
              "      <td>facial-expressions_2868584k.jpg</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>628</td>\n",
              "      <td>facial-expressions_2868585k.jpg</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>628</td>\n",
              "      <td>facial-expressions_2868588k.jpg</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13690 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      user.id                            image    emotion\n",
              "146       302                 AJ_Cook_0001.jpg  happiness\n",
              "147       302                AJ_Lamas_0001.jpg  happiness\n",
              "4       dwdii           Aaron_Eckhart_0001.jpg    neutral\n",
              "5         302             Aaron_Guiel_0001.jpg  happiness\n",
              "6         302         Aaron_Patterson_0001.jpg    neutral\n",
              "...       ...                              ...        ...\n",
              "12768   dwdii      Zydrunas_Ilgauskas_0001.jpg    neutral\n",
              "3         628  facial-expressions_2868582k.jpg       fear\n",
              "2         628  facial-expressions_2868584k.jpg    disgust\n",
              "1         628  facial-expressions_2868585k.jpg   surprise\n",
              "0         628  facial-expressions_2868588k.jpg      anger\n",
              "\n",
              "[13690 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PjUpL7cdyVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_of_entries = (13690*8)//10\n",
        "batch_size = 32\n",
        "IMG_HEIGHT = 300\n",
        "IMG_WIDTH = 300\n",
        "epochs = 15\n",
        "matrix = legend.to_numpy()#in matrix format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN2D8yEMoGpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image=[]\n",
        "emotions=[]\n",
        "for i in range(no_of_entries):\n",
        "  emotions.append(matrix[i][2])\n",
        "  emotions[i].lower()\n",
        "  path=path_to_images+\"/\"+matrix[i][1]\n",
        "  img=load_img(path,color_mode=\"grayscale\",target_size=(300,300))\n",
        "  img1 = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img2 = tf.convert_to_tensor(img1)\n",
        "  img2 = tf.image.convert_image_dtype(img2, tf.float32)\n",
        "  img2 = img2/255\n",
        "  image.append(img2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFanch7yogZk",
        "colab_type": "code",
        "outputId": "855683bc-7ac4-44e3-ca12-255cc673acee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(image)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYR092RG28Me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_set = set(emotions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJf9c5-k3AaO",
        "colab_type": "code",
        "outputId": "7a555464-62e7-445f-fdff-92d8835bcda3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "emotion_set"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ANGER',\n",
              " 'DISGUST',\n",
              " 'FEAR',\n",
              " 'HAPPINESS',\n",
              " 'NEUTRAL',\n",
              " 'SADNESS',\n",
              " 'SURPRISE',\n",
              " 'anger',\n",
              " 'contempt',\n",
              " 'disgust',\n",
              " 'fear',\n",
              " 'happiness',\n",
              " 'neutral',\n",
              " 'sadness',\n",
              " 'surprise'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RLxf9JT3cyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_vec = []\n",
        "for i in range(no_of_entries):\n",
        "  if emotions[i] == 'ANGER' or emotions[i]=='anger':\n",
        "    emotion_vec.append(0)\n",
        "  if emotions[i] == 'NEUTRAL' or emotions[i]=='neutral':\n",
        "    emotion_vec.append(1)\n",
        "  if emotions[i] == 'CONTEMPT' or emotions[i]=='contempt':\n",
        "    emotion_vec.append(2)\n",
        "  if emotions[i] == 'DISGUST' or emotions[i]=='disgust':\n",
        "    emotion_vec.append(3)\n",
        "  if emotions[i] == 'FEAR' or emotions[i]=='fear':\n",
        "    emotion_vec.append(4)\n",
        "  if emotions[i] == 'HAPPINESS' or emotions[i]=='happiness':\n",
        "    emotion_vec.append(5)\n",
        "  if emotions[i] == 'SADNESS' or emotions[i]=='sadness':\n",
        "    emotion_vec.append(6)\n",
        "  if emotions[i] == 'SURPRISE' or emotions[i]=='surprise':\n",
        "    emotion_vec.append(7)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKOOfQAxyCXr",
        "colab_type": "code",
        "outputId": "a1275daf-c05e-43a7-c535-fbdf6cf687de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "emotion_vec[100]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ove10Nz86Wig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8ec1cce-41aa-4822-ad91-fd08e6b15dfd"
      },
      "source": [
        "emotions[100]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happiness'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr6IzTqc6kgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_vec = tf.keras.utils.to_categorical(emotion_vec)\n",
        "emotion_vec = tf.convert_to_tensor(emotion_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ihoZMQ6vhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e8620b4-8c7e-4fef-aef1-335884610d90"
      },
      "source": [
        "emotion_vec[100]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6_mPGWIDVs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_image = tf.data.Dataset.from_tensor_slices((image,emotion_vec))\n",
        "dataset_image = dataset_image.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsRY0TR2KtBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,1)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(8,activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St-Qstv4KwWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJrS0US_KzEs",
        "colab_type": "code",
        "outputId": "5aec5468-1b96-43c3-91a0-f5e95d9cfd95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 300, 300, 16)      160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 150, 150, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 150, 150, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 75, 75, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 37, 37, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 87616)             0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               44859904  \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 44,887,304\n",
            "Trainable params: 44,887,304\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH0TsGGP9Ilz",
        "colab_type": "code",
        "outputId": "0c53e0eb-92ef-457b-9d17-87f0c478bc30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "model.fit(dataset_image,batch_size=batch_size,epochs=10)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 1.0800 - accuracy: 0.5001\n",
            "Epoch 2/10\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 1.0921 - accuracy: 0.4850\n",
            "Epoch 3/10\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 1.0857 - accuracy: 0.4879\n",
            "Epoch 4/10\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 1.0615 - accuracy: 0.5237\n",
            "Epoch 5/10\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.9395 - accuracy: 0.5993\n",
            "Epoch 6/10\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.7363 - accuracy: 0.7309\n",
            "Epoch 7/10\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.6452 - accuracy: 0.7630\n",
            "Epoch 8/10\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.5248 - accuracy: 0.8074\n",
            "Epoch 9/10\n",
            "342/342 [==============================] - 14s 40ms/step - loss: 0.4218 - accuracy: 0.8468\n",
            "Epoch 10/10\n",
            "342/342 [==============================] - 14s 41ms/step - loss: 0.3034 - accuracy: 0.8944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f57ce55a160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}