{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinCopyProject-II.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek203/E-Abhishek/blob/master/FinCopyProject_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPV6qtjVlzun",
        "colab_type": "code",
        "outputId": "5c0d0efb-8d8f-4da8-8034-2ffe6c7e3093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv1D, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout \n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8y3QnQYmm1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://drive.google.com/open?id=1QRkgQ0dzP_Occx2j-STNl8D2qz-24gM5\"\n",
        "url_id = \"1QRkgQ0dzP_Occx2j-STNl8D2qz-24gM5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMnXLtqsnNOl",
        "colab_type": "code",
        "outputId": "b93c93ca-7d2e-42ce-968b-903d35005d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.7.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (46.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8hGAC-AnRsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHlKYlminV41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-t7xbDznd2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id' : url_id})\n",
        "downloaded.GetContentFile('Emotions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfyDIvy7oRDj",
        "colab_type": "code",
        "outputId": "3e29f669-8935-4df2-fa8d-aec589c44dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "data = pd.read_csv('Emotions.csv')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>86 104 151 119 35 26 36 36 35 33 31 33 32 34 3...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>30 30 28 30 27 23 11 5 6 9 13 20 34 52 75 106 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>226 226 225 223 223 216 210 214 208 198 192 18...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>180 133 85 75 63 63 66 67 66 58 51 66 84 102 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>14 15 32 72 82 113 180 147 45 49 54 74 67 79 7...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  86 104 151 119 35 26 36 36 35 33 31 33 32 34 3...  Training\n",
              "1        4  30 30 28 30 27 23 11 5 6 9 13 20 34 52 75 106 ...  Training\n",
              "2        3  226 226 225 223 223 216 210 214 208 198 192 18...  Training\n",
              "3        4  180 133 85 75 63 63 66 67 66 58 51 66 84 102 1...  Training\n",
              "4        0  14 15 32 72 82 113 180 147 45 49 54 74 67 79 7...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsMGIuO2upJg",
        "colab_type": "code",
        "outputId": "44798289-e342-4d58-de74-ea8f320d99a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for i in range(data.shape[0]):\n",
        "  pix_list = [float(x) for x in data['pixels'][i].split(' ')]\n",
        "  # pix_list = norm_list(pix_list)\n",
        "  pix_arr = np.array(pix_list)\n",
        "  pix_img = np.reshape(pix_arr, (48, 48))\n",
        "  pix_img_to_list = pix_img.tolist()\n",
        "  data['pixels'][i] = pix_img_to_list\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[[86.0, 104.0, 151.0, 119.0, 35.0, 26.0, 36.0,...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>[[30.0, 30.0, 28.0, 30.0, 27.0, 23.0, 11.0, 5....</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[[226.0, 226.0, 225.0, 223.0, 223.0, 216.0, 21...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[[180.0, 133.0, 85.0, 75.0, 63.0, 63.0, 66.0, ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[[14.0, 15.0, 32.0, 72.0, 82.0, 113.0, 180.0, ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  [[86.0, 104.0, 151.0, 119.0, 35.0, 26.0, 36.0,...  Training\n",
              "1        4  [[30.0, 30.0, 28.0, 30.0, 27.0, 23.0, 11.0, 5....  Training\n",
              "2        3  [[226.0, 226.0, 225.0, 223.0, 223.0, 216.0, 21...  Training\n",
              "3        4  [[180.0, 133.0, 85.0, 75.0, 63.0, 63.0, 66.0, ...  Training\n",
              "4        0  [[14.0, 15.0, 32.0, 72.0, 82.0, 113.0, 180.0, ...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1JsyUF4vvNq",
        "colab_type": "code",
        "outputId": "523b98eb-1359-4d6e-b328-638cc15ee9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['pixels'][0][0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNEsClrgodPC",
        "colab_type": "code",
        "outputId": "13153140-f789-457f-c110-b6b7136d228f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "dftrain = data[data['Usage'] == 'Training']\n",
        "dfdev = data[data['Usage'] == 'PublicTest']\n",
        "dftest = data[data['Usage'] == 'PrivateTest']\n",
        "print(dftrain.shape, dfdev.shape, dftest.shape)\n",
        "\n",
        "dftrain.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30694, 3) (4089, 3) (4122, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[[86.0, 104.0, 151.0, 119.0, 35.0, 26.0, 36.0,...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>[[30.0, 30.0, 28.0, 30.0, 27.0, 23.0, 11.0, 5....</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[[226.0, 226.0, 225.0, 223.0, 223.0, 216.0, 21...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[[180.0, 133.0, 85.0, 75.0, 63.0, 63.0, 66.0, ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[[14.0, 15.0, 32.0, 72.0, 82.0, 113.0, 180.0, ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  [[86.0, 104.0, 151.0, 119.0, 35.0, 26.0, 36.0,...  Training\n",
              "1        4  [[30.0, 30.0, 28.0, 30.0, 27.0, 23.0, 11.0, 5....  Training\n",
              "2        3  [[226.0, 226.0, 225.0, 223.0, 223.0, 216.0, 21...  Training\n",
              "3        4  [[180.0, 133.0, 85.0, 75.0, 63.0, 63.0, 66.0, ...  Training\n",
              "4        0  [[14.0, 15.0, 32.0, 72.0, 82.0, 113.0, 180.0, ...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYyMG_F7opIj",
        "colab_type": "code",
        "outputId": "fad5f363-0a10-4246-b904-7e2741d6576a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "print(dftrain.emotion.hist(bins = 20))\n",
        "# print(dfdev.emotion.hist(bins = 20))\n",
        "# print(dftest.emotion.hist(bins = 20))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9BsAuxoubhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_count = dftrain.shape[0]\n",
        "dev_count = dfdev.shape[0]\n",
        "test_count = dftest.shape[0]\n",
        "img_h = 48\n",
        "img_w = 48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH_rqWBrsnbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(dftrain['emotion'])\n",
        "y_dev = np.array(dfdev['emotion'])\n",
        "y_test = np.array(dftest['emotion'])\n",
        "\n",
        "Y_train = tf.keras.utils.to_categorical(y_train, num_classes = 7)\n",
        "Y_dev = tf.keras.utils.to_categorical(y_dev, num_classes = 7)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, num_classes = 7)\n",
        "\n",
        "# print(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g93ZOJme1TCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_X(df, start, end):\n",
        "  x_list = []\n",
        "  for i in range(start, end):\n",
        "    x_list.append(df['pixels'][i])\n",
        "  X = np.array(x_list)\n",
        "  X = X / 255\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nap4G4vXuCoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = get_X(dftrain, 0, train_count)\n",
        "X_dev = get_X(dfdev, train_count, train_count + dev_count)\n",
        "X_test = get_X(dftest, train_count + dev_count, train_count + dev_count + test_count)\n",
        "\n",
        "X_train.shape = (30694, 48, 48, 1)\n",
        "X_dev.shape = (4089, 48, 48, 1)\n",
        "X_test.shape = (4122, 48, 48, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twQIOAbb0Utc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_Model(input_shape):\n",
        "  X_input = Input(input_shape)\n",
        "  X = X_input\n",
        "  X = Conv2D(filters = 64, kernel_size = (3, 3), strides = 1, padding = \"same\", name = \"CONV1\")(X)\n",
        "  X = BatchNormalization(axis = 3, name = \"BN1\")(X)\n",
        "  X = Activation('relu')(X)  \n",
        "  X = Conv2D(filters = 64, kernel_size = (3, 3), strides = 1, name = \"CONV2\")(X)\n",
        "  X = BatchNormalization(axis = 3, name = \"BN2\")(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2, 2), name = \"POOL1\")(X)\n",
        "  X = Dropout(0.05)(X)\n",
        "  X = Conv2D(filters = 128, kernel_size = (3, 3), strides = 1, padding = \"same\", name = \"CONV3\")(X)\n",
        "  X = BatchNormalization(axis = 3, name = \"BN3\")(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Conv2D(filters = 128, kernel_size = (3, 3), strides = 1, name = \"CONV4\")(X)\n",
        "  X = BatchNormalization(axis = 3, name = \"BN4\")(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, padding = \"same\", name = \"CONV5\")(X)\n",
        "  X = BatchNormalization(axis = 3, name = \"BN5\")(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = Conv2D(filters = 256, kernel_size = (3, 3), strides = 1, name = \"CONV6\")(X)\n",
        "  X = BatchNormalization(axis = 3, name = \"BN6\")(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2, 2), name = \"POOL2\")(X)\n",
        "  X = Dropout(0.05)(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(1024, activation = \"relu\", name = \"FC1\", kernel_regularizer = tf.keras.regularizers.l2(0.001))(X)\n",
        "  X = Dropout(0.1)(X)\n",
        "  X = Dense(7, activation = \"softmax\", name = \"Output\")(X)\n",
        "\n",
        "  model = Model(inputs = X_input, outputs = X, name = \"Emotion_Model\")\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVHjxWyv65gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Emotion_Model = train_Model((48, 48, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03GLRYOm8LsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Emotion_Model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCC3dk9JKY1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Emotion_Model.fit(X_train, Y_train, batch_size = 64, epochs = 5)  # total = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulmL5yDxK3-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Emotion_Model.evaluate(X_dev, Y_dev, batch_size = 64, verbose = 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_2guupfUFLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Emotion_Model.evaluate(X_test, Y_test, batch_size = 64, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}